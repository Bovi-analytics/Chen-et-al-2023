{"cells":[{"cell_type":"code","source":["pip install mlflow"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"46cd166d-c7e0-4379-b515-4b1ac4b8161a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Python interpreter will be restarted.\nCollecting mlflow\n  Downloading mlflow-1.30.0-py3-none-any.whl (17.0 MB)\nCollecting cloudpickle<3\n  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\nCollecting databricks-cli<1,>=0.8.7\n  Downloading databricks-cli-0.17.3.tar.gz (77 kB)\nCollecting click<9,>=7.0\n  Downloading click-8.1.3-py3-none-any.whl (96 kB)\nRequirement already satisfied: pytz<2023 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2020.5)\nCollecting sqlparse<1,>=0.4.0\n  Downloading sqlparse-0.4.3-py3-none-any.whl (42 kB)\nRequirement already satisfied: entrypoints<1 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.3)\nRequirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2.25.1)\nRequirement already satisfied: numpy<2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.20.1)\nRequirement already satisfied: pandas<2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.2.4)\nCollecting docker<7,>=4.0.0\n  Downloading docker-6.0.0-py3-none-any.whl (147 kB)\nCollecting importlib-metadata!=4.7.0,<6,>=3.7.0\n  Downloading importlib_metadata-5.0.0-py3-none-any.whl (21 kB)\nRequirement already satisfied: protobuf<5,>=3.12.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (3.17.2)\nCollecting prometheus-flask-exporter<1\n  Downloading prometheus_flask_exporter-0.20.3-py3-none-any.whl (18 kB)\nCollecting pyyaml<7,>=5.1\n  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\nCollecting alembic<2\n  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\nCollecting gitpython<4,>=2.1.0\n  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.6.2)\nCollecting sqlalchemy<2,>=1.4.0\n  Downloading SQLAlchemy-1.4.42-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\nCollecting gunicorn<21\n  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\nRequirement already satisfied: packaging<22 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (20.9)\nCollecting Flask<3\n  Downloading Flask-2.2.2-py3-none-any.whl (101 kB)\nCollecting querystring-parser<2\n  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\nCollecting importlib-resources\n  Downloading importlib_resources-5.10.0-py3-none-any.whl (34 kB)\nCollecting Mako\n  Downloading Mako-1.2.3-py3-none-any.whl (78 kB)\nCollecting pyjwt>=1.7.0\n  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\nCollecting oauthlib>=3.1.0\n  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\nCollecting tabulate>=0.7.7\n  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\nRequirement already satisfied: six>=1.10.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.15.0)\nCollecting websocket-client>=0.32.0\n  Downloading websocket_client-1.4.1-py3-none-any.whl (55 kB)\nCollecting urllib3>=1.26.0\n  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\nCollecting requests<3,>=2.17.3\n  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\nCollecting itsdangerous>=2.0\n  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\nCollecting Jinja2>=3.0\n  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\nCollecting Werkzeug>=2.2.2\n  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\nCollecting gitdb<5,>=4.0.1\n  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\nCollecting smmap<6,>=3.0.1\n  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\nRequirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.8/dist-packages (from gunicorn<21->mlflow) (52.0.0)\nCollecting zipp>=0.5\n  Downloading zipp-3.10.0-py3-none-any.whl (6.2 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.8/site-packages (from Jinja2>=3.0->Flask<3->mlflow) (2.0.1)\nRequirement already satisfied: pyparsing>=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging<22->mlflow) (2.4.7)\nRequirement already satisfied: python-dateutil>=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from pandas<2->mlflow) (2.8.1)\nRequirement already satisfied: prometheus-client in /databricks/python3/lib/python3.8/site-packages (from prometheus-flask-exporter<1->mlflow) (0.10.1)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow) (2020.12.5)\nCollecting charset-normalizer<3,>=2\n  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow) (2.10)\nCollecting greenlet!=0.4.17\n  Downloading greenlet-1.1.3.post0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\nCollecting MarkupSafe>=2.0\n  Downloading MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nBuilding wheels for collected packages: databricks-cli\n  Building wheel for databricks-cli (setup.py): started\n  Building wheel for databricks-cli (setup.py): finished with status 'done'\n  Created wheel for databricks-cli: filename=databricks_cli-0.17.3-py3-none-any.whl size=139099 sha256=176820fc986ba22954eb6c4b6503c05cf44865a7fc02c51fa39343a19750e9b4\n  Stored in directory: /root/.cache/pip/wheels/58/40/7c/d021d51dac18bfd095fb6837572ad2e6f1a34d221f4b1d976b\nSuccessfully built databricks-cli\nInstalling collected packages: zipp, MarkupSafe, Werkzeug, urllib3, smmap, Jinja2, itsdangerous, importlib-metadata, greenlet, click, charset-normalizer, websocket-client, tabulate, sqlalchemy, requests, pyjwt, oauthlib, Mako, importlib-resources, gitdb, Flask, sqlparse, querystring-parser, pyyaml, prometheus-flask-exporter, gunicorn, gitpython, docker, databricks-cli, cloudpickle, alembic, mlflow\n  Attempting uninstall: MarkupSafe\n    Found existing installation: MarkupSafe 2.0.1\n    Not uninstalling markupsafe at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-0dcc49a9-6c11-40cf-848c-c699689b09d0\n    Can't uninstall 'MarkupSafe'. No files were found to uninstall.\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.25.11\n    Not uninstalling urllib3 at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-0dcc49a9-6c11-40cf-848c-c699689b09d0\n    Can't uninstall 'urllib3'. No files were found to uninstall.\n  Attempting uninstall: Jinja2\n    Found existing installation: Jinja2 2.11.3\n    Not uninstalling jinja2 at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-0dcc49a9-6c11-40cf-848c-c699689b09d0\n    Can't uninstall 'Jinja2'. No files were found to uninstall.\n  Attempting uninstall: requests\n    Found existing installation: requests 2.25.1\n    Not uninstalling requests at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-0dcc49a9-6c11-40cf-848c-c699689b09d0\n    Can't uninstall 'requests'. No files were found to uninstall.\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbotocore 1.19.7 requires urllib3<1.26,>=1.25.4; python_version != \"3.4\", but you have urllib3 1.26.12 which is incompatible.\nSuccessfully installed Flask-2.2.2 Jinja2-3.1.2 Mako-1.2.3 MarkupSafe-2.1.1 Werkzeug-2.2.2 alembic-1.8.1 charset-normalizer-2.1.1 click-8.1.3 cloudpickle-2.2.0 databricks-cli-0.17.3 docker-6.0.0 gitdb-4.0.9 gitpython-3.1.29 greenlet-1.1.3.post0 gunicorn-20.1.0 importlib-metadata-5.0.0 importlib-resources-5.10.0 itsdangerous-2.1.2 mlflow-1.30.0 oauthlib-3.2.2 prometheus-flask-exporter-0.20.3 pyjwt-2.6.0 pyyaml-6.0 querystring-parser-1.2.4 requests-2.28.1 smmap-5.0.0 sqlalchemy-1.4.42 sqlparse-0.4.3 tabulate-0.9.0 urllib3-1.26.12 websocket-client-1.4.1 zipp-3.10.0\nPython interpreter will be restarted.\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Python interpreter will be restarted.\nCollecting mlflow\n  Downloading mlflow-1.30.0-py3-none-any.whl (17.0 MB)\nCollecting cloudpickle<3\n  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\nCollecting databricks-cli<1,>=0.8.7\n  Downloading databricks-cli-0.17.3.tar.gz (77 kB)\nCollecting click<9,>=7.0\n  Downloading click-8.1.3-py3-none-any.whl (96 kB)\nRequirement already satisfied: pytz<2023 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2020.5)\nCollecting sqlparse<1,>=0.4.0\n  Downloading sqlparse-0.4.3-py3-none-any.whl (42 kB)\nRequirement already satisfied: entrypoints<1 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.3)\nRequirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2.25.1)\nRequirement already satisfied: numpy<2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.20.1)\nRequirement already satisfied: pandas<2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.2.4)\nCollecting docker<7,>=4.0.0\n  Downloading docker-6.0.0-py3-none-any.whl (147 kB)\nCollecting importlib-metadata!=4.7.0,<6,>=3.7.0\n  Downloading importlib_metadata-5.0.0-py3-none-any.whl (21 kB)\nRequirement already satisfied: protobuf<5,>=3.12.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (3.17.2)\nCollecting prometheus-flask-exporter<1\n  Downloading prometheus_flask_exporter-0.20.3-py3-none-any.whl (18 kB)\nCollecting pyyaml<7,>=5.1\n  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\nCollecting alembic<2\n  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\nCollecting gitpython<4,>=2.1.0\n  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.6.2)\nCollecting sqlalchemy<2,>=1.4.0\n  Downloading SQLAlchemy-1.4.42-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\nCollecting gunicorn<21\n  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\nRequirement already satisfied: packaging<22 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (20.9)\nCollecting Flask<3\n  Downloading Flask-2.2.2-py3-none-any.whl (101 kB)\nCollecting querystring-parser<2\n  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\nCollecting importlib-resources\n  Downloading importlib_resources-5.10.0-py3-none-any.whl (34 kB)\nCollecting Mako\n  Downloading Mako-1.2.3-py3-none-any.whl (78 kB)\nCollecting pyjwt>=1.7.0\n  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\nCollecting oauthlib>=3.1.0\n  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\nCollecting tabulate>=0.7.7\n  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\nRequirement already satisfied: six>=1.10.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.15.0)\nCollecting websocket-client>=0.32.0\n  Downloading websocket_client-1.4.1-py3-none-any.whl (55 kB)\nCollecting urllib3>=1.26.0\n  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\nCollecting requests<3,>=2.17.3\n  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\nCollecting itsdangerous>=2.0\n  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\nCollecting Jinja2>=3.0\n  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\nCollecting Werkzeug>=2.2.2\n  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\nCollecting gitdb<5,>=4.0.1\n  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\nCollecting smmap<6,>=3.0.1\n  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\nRequirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.8/dist-packages (from gunicorn<21->mlflow) (52.0.0)\nCollecting zipp>=0.5\n  Downloading zipp-3.10.0-py3-none-any.whl (6.2 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.8/site-packages (from Jinja2>=3.0->Flask<3->mlflow) (2.0.1)\nRequirement already satisfied: pyparsing>=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging<22->mlflow) (2.4.7)\nRequirement already satisfied: python-dateutil>=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from pandas<2->mlflow) (2.8.1)\nRequirement already satisfied: prometheus-client in /databricks/python3/lib/python3.8/site-packages (from prometheus-flask-exporter<1->mlflow) (0.10.1)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow) (2020.12.5)\nCollecting charset-normalizer<3,>=2\n  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow) (2.10)\nCollecting greenlet!=0.4.17\n  Downloading greenlet-1.1.3.post0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\nCollecting MarkupSafe>=2.0\n  Downloading MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nBuilding wheels for collected packages: databricks-cli\n  Building wheel for databricks-cli (setup.py): started\n  Building wheel for databricks-cli (setup.py): finished with status 'done'\n  Created wheel for databricks-cli: filename=databricks_cli-0.17.3-py3-none-any.whl size=139099 sha256=176820fc986ba22954eb6c4b6503c05cf44865a7fc02c51fa39343a19750e9b4\n  Stored in directory: /root/.cache/pip/wheels/58/40/7c/d021d51dac18bfd095fb6837572ad2e6f1a34d221f4b1d976b\nSuccessfully built databricks-cli\nInstalling collected packages: zipp, MarkupSafe, Werkzeug, urllib3, smmap, Jinja2, itsdangerous, importlib-metadata, greenlet, click, charset-normalizer, websocket-client, tabulate, sqlalchemy, requests, pyjwt, oauthlib, Mako, importlib-resources, gitdb, Flask, sqlparse, querystring-parser, pyyaml, prometheus-flask-exporter, gunicorn, gitpython, docker, databricks-cli, cloudpickle, alembic, mlflow\n  Attempting uninstall: MarkupSafe\n    Found existing installation: MarkupSafe 2.0.1\n    Not uninstalling markupsafe at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-0dcc49a9-6c11-40cf-848c-c699689b09d0\n    Can't uninstall 'MarkupSafe'. No files were found to uninstall.\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.25.11\n    Not uninstalling urllib3 at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-0dcc49a9-6c11-40cf-848c-c699689b09d0\n    Can't uninstall 'urllib3'. No files were found to uninstall.\n  Attempting uninstall: Jinja2\n    Found existing installation: Jinja2 2.11.3\n    Not uninstalling jinja2 at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-0dcc49a9-6c11-40cf-848c-c699689b09d0\n    Can't uninstall 'Jinja2'. No files were found to uninstall.\n  Attempting uninstall: requests\n    Found existing installation: requests 2.25.1\n    Not uninstalling requests at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-0dcc49a9-6c11-40cf-848c-c699689b09d0\n    Can't uninstall 'requests'. No files were found to uninstall.\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbotocore 1.19.7 requires urllib3<1.26,>=1.25.4; python_version != \"3.4\", but you have urllib3 1.26.12 which is incompatible.\nSuccessfully installed Flask-2.2.2 Jinja2-3.1.2 Mako-1.2.3 MarkupSafe-2.1.1 Werkzeug-2.2.2 alembic-1.8.1 charset-normalizer-2.1.1 click-8.1.3 cloudpickle-2.2.0 databricks-cli-0.17.3 docker-6.0.0 gitdb-4.0.9 gitpython-3.1.29 greenlet-1.1.3.post0 gunicorn-20.1.0 importlib-metadata-5.0.0 importlib-resources-5.10.0 itsdangerous-2.1.2 mlflow-1.30.0 oauthlib-3.2.2 prometheus-flask-exporter-0.20.3 pyjwt-2.6.0 pyyaml-6.0 querystring-parser-1.2.4 requests-2.28.1 smmap-5.0.0 sqlalchemy-1.4.42 sqlparse-0.4.3 tabulate-0.9.0 urllib3-1.26.12 websocket-client-1.4.1 zipp-3.10.0\nPython interpreter will be restarted.\n"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\nspark.sparkContext.hadoopConfiguration.set(\n  \"fs.azure.account.key.bovianalytics.blob.core.windows.net\",\n  \"a3/QhTcHik/gwnSCI/eBdjK1GruaFdeELpSzdnwKAKe6LebTUz6Ca4cKwUUWFdWO2JmUAFdaq/N6VMc/OXLdPg==\"\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"83f4d41e-7866-46dd-8bdd-740d40ff2ca1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import to_date,col,avg\nfrom pyspark.sql.types import LongType, StringType, StructField, StructType, BooleanType, ArrayType, IntegerType, DoubleType, FloatType, TimestampType\nimport pyspark.sql.functions as F\nfrom pyspark.sql import Window\nfrom pprint import pprint as pp\nimport pandas as pd\nimport json\nfrom urllib.request import  urlopen\nimport requests\nimport statsmodels.api as sm"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6c55bb6c-0316-449f-b337-bbe33a420ae6","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#Read TrainTestData"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"70b34a27-c21f-4670-96db-8df2c9f86a48","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["TrainDf = spark. \\\n  read. \\\n  parquet('wasbs://gpluse-cluster-2@bovianalytics.blob.core.windows.net/Projects/ChenYoungYan/11022022/Output/0405Split/TrainTestData/TrainDf125/')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f654db42-d168-47ea-9635-8ed16414e965","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["TestDf = spark. \\\n  read. \\\n  parquet('wasbs://gpluse-cluster-2@bovianalytics.blob.core.windows.net/Projects/ChenYoungYan/11022022/Output/0405Split/TrainTestData/TestDf125/')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4a6af84c-94d4-4b29-bf1f-43fcb2a63240","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["x_train = TrainDf.select(\"features\").\\\n    rdd.flatMap(lambda x: x).collect()\ny_train = TrainDf.select(\"Decay305Vetor\").\\\n    rdd.flatMap(lambda x: x).collect()\n\nx_test = TestDf.select(\"features\").\\\n    rdd.flatMap(lambda x: x).collect()\ny_test = TestDf.select(\"Decay305Vetor\").\\\n    rdd.flatMap(lambda x: x).collect()\n\n\nfeatureList =['MultiparousCow','Winter','Spring','Autumn','Magnitude','TimeToPeakYield','Offset','Decay','TestDayMilkYield','AgeInMonths','HM305','MeanMagnitude', 'MeanTimeToPeakYield', 'MeanOffset', 'MeanDecay']"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"441d2cd4-4f90-4682-9887-2f111baa94a6","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# check reference"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"909b11cc-8676-4271-884c-97f7d8d8ae3f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["sorted(set([(i[0], i[1]) for i in TrainDf.select(\"CalvingSeason\", \"CalvingSeasonEncode\").collect()]),\n    key=lambda x: x[0])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"67b48db8-cdc4-43dc-afab-26d5d7ffdf64","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Out[8]: [('Autumn', SparseVector(3, {0: 1.0})),\n ('Spring', SparseVector(3, {2: 1.0})),\n ('Summer', SparseVector(3, {})),\n ('Winter', SparseVector(3, {1: 1.0}))]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[8]: [('Autumn', SparseVector(3, {0: 1.0})),\n ('Spring', SparseVector(3, {2: 1.0})),\n ('Summer', SparseVector(3, {})),\n ('Winter', SparseVector(3, {1: 1.0}))]"]}}],"execution_count":0},{"cell_type":"code","source":["sorted(set([(i[0], i[1]) for i in TestDf.select(\"CalvingSeason\", \"CalvingSeasonEncode\").collect()]),\n    key=lambda x: x[0])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0ca3e6da-b4b8-4c1e-9769-50932759b903","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Out[9]: [('Autumn', SparseVector(3, {0: 1.0})),\n ('Spring', SparseVector(3, {})),\n ('Summer', SparseVector(3, {2: 1.0})),\n ('Winter', SparseVector(3, {1: 1.0}))]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[9]: [('Autumn', SparseVector(3, {0: 1.0})),\n ('Spring', SparseVector(3, {})),\n ('Summer', SparseVector(3, {2: 1.0})),\n ('Winter', SparseVector(3, {1: 1.0}))]"]}}],"execution_count":0},{"cell_type":"code","source":["sorted(set([(i[0], i[1]) for i in TrainDf.select(\"ParityGroup\",\"ParityGroupEncode\").collect()]),\n    key=lambda x: x[0])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"641133c9-9756-4115-a2b9-f38f72aeb418","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Out[10]: [('MultiparousCow', SparseVector(1, {0: 1.0})),\n ('PrimiparousCow', SparseVector(1, {}))]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[10]: [('MultiparousCow', SparseVector(1, {0: 1.0})),\n ('PrimiparousCow', SparseVector(1, {}))]"]}}],"execution_count":0},{"cell_type":"code","source":["sorted(set([(i[0], i[1]) for i in TestDf.select(\"ParityGroup\",\"ParityGroupEncode\").collect()]),\n    key=lambda x: x[0])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7c813c44-d2e3-4cc6-99ba-147d39bae5a0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Out[11]: [('MultiparousCow', SparseVector(1, {0: 1.0})),\n ('PrimiparousCow', SparseVector(1, {}))]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[11]: [('MultiparousCow', SparseVector(1, {0: 1.0})),\n ('PrimiparousCow', SparseVector(1, {}))]"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Model building"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0c0936b5-47a6-455d-8db8-f9a0f781dd67","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import mlflow\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import RandomizedSearchCV,GridSearchCV\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression,Ridge,Lasso\nfrom sklearn.model_selection import cross_val_score, cross_validate\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score,mean_absolute_percentage_error,mean_absolute_error"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"60df22c8-e6ad-4879-9b3c-93052c5b6711","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Linear Regression"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"89913b8c-7e4d-4a0e-bd0d-4c41f65e3635","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["X = sm.add_constant(x_train)\nmod = sm.OLS(y_train,X)\nres = mod.fit()\nprint(res.summary())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"020606e2-385a-478e-a4f0-1c6e7f821cb2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.376\nModel:                            OLS   Adj. R-squared:                  0.375\nMethod:                 Least Squares   F-statistic:                     411.6\nDate:                Sun, 23 Oct 2022   Prob (F-statistic):               0.00\nTime:                        13:44:50   Log-Likelihood:                 61990.\nNo. Observations:               10277   AIC:                        -1.239e+05\nDf Residuals:                   10261   BIC:                        -1.238e+05\nDf Model:                          15                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0019   3.88e-05     48.797      0.000       0.002       0.002\nx1          1.484e-05    5.1e-05      0.291      0.771    -8.5e-05       0.000\nx2         -4.533e-05   1.61e-05     -2.808      0.005    -7.7e-05   -1.37e-05\nx3             0.0003   1.66e-05     17.017      0.000       0.000       0.000\nx4             0.0003   1.68e-05     15.186      0.000       0.000       0.000\nx5             0.0003   1.68e-05     17.091      0.000       0.000       0.000\nx6         -9.109e-05   8.25e-06    -11.040      0.000      -0.000   -7.49e-05\nx7          2.875e-05   9.86e-06      2.917      0.004    9.43e-06    4.81e-05\nx8          6.379e-05   1.01e-05      6.308      0.000     4.4e-05    8.36e-05\nx9            -0.0004   1.55e-05    -23.919      0.000      -0.000      -0.000\nx10         9.133e-05   1.26e-05      7.270      0.000    6.67e-05       0.000\nx11        -6.509e-05   1.63e-05     -3.984      0.000   -9.71e-05   -3.31e-05\nx12          6.65e-05   2.37e-05      2.805      0.005       2e-05       0.000\nx13        -3.294e-05   1.57e-05     -2.104      0.035   -6.36e-05   -2.26e-06\nx14        -4.274e-06   6.33e-06     -0.675      0.500   -1.67e-05    8.14e-06\nx15         7.943e-05   1.35e-05      5.869      0.000    5.29e-05       0.000\n==============================================================================\nOmnibus:                       25.134   Durbin-Watson:                   1.950\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               24.308\nSkew:                           0.100   Prob(JB):                     5.27e-06\nKurtosis:                       2.869   Cond. No.                         24.8\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.376\nModel:                            OLS   Adj. R-squared:                  0.375\nMethod:                 Least Squares   F-statistic:                     411.6\nDate:                Sun, 23 Oct 2022   Prob (F-statistic):               0.00\nTime:                        13:44:50   Log-Likelihood:                 61990.\nNo. Observations:               10277   AIC:                        -1.239e+05\nDf Residuals:                   10261   BIC:                        -1.238e+05\nDf Model:                          15                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0019   3.88e-05     48.797      0.000       0.002       0.002\nx1          1.484e-05    5.1e-05      0.291      0.771    -8.5e-05       0.000\nx2         -4.533e-05   1.61e-05     -2.808      0.005    -7.7e-05   -1.37e-05\nx3             0.0003   1.66e-05     17.017      0.000       0.000       0.000\nx4             0.0003   1.68e-05     15.186      0.000       0.000       0.000\nx5             0.0003   1.68e-05     17.091      0.000       0.000       0.000\nx6         -9.109e-05   8.25e-06    -11.040      0.000      -0.000   -7.49e-05\nx7          2.875e-05   9.86e-06      2.917      0.004    9.43e-06    4.81e-05\nx8          6.379e-05   1.01e-05      6.308      0.000     4.4e-05    8.36e-05\nx9            -0.0004   1.55e-05    -23.919      0.000      -0.000      -0.000\nx10         9.133e-05   1.26e-05      7.270      0.000    6.67e-05       0.000\nx11        -6.509e-05   1.63e-05     -3.984      0.000   -9.71e-05   -3.31e-05\nx12          6.65e-05   2.37e-05      2.805      0.005       2e-05       0.000\nx13        -3.294e-05   1.57e-05     -2.104      0.035   -6.36e-05   -2.26e-06\nx14        -4.274e-06   6.33e-06     -0.675      0.500   -1.67e-05    8.14e-06\nx15         7.943e-05   1.35e-05      5.869      0.000    5.29e-05       0.000\n==============================================================================\nOmnibus:                       25.134   Durbin-Watson:                   1.950\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               24.308\nSkew:                           0.100   Prob(JB):                     5.27e-06\nKurtosis:                       2.869   Cond. No.                         24.8\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### train"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"85654202-e044-457b-9a7b-50e09bf88907","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["with mlflow.start_run(run_name = 'Linear Regression') as run:\n    \n    \n    # model\n    \n    lm = LinearRegression()\n    lm.fit(x_train,y_train)\n    coeffs = lm.coef_.tolist()[0]\n    y_pred = lm.predict(x_train)\n   \n    # log parameters\n    mlflow.log_param('data','train')\n    mlflow.log_param('type','whole')\n    \n    plt.figure(figsize=(20,7))\n    plt.bar(featureList,coeffs)\n    plt.axhline(y=0, color='r', linestyle='--')\n    plt.ylabel('β', fontsize=20,rotation=0)\n    plt.xticks(rotation=25,fontsize= 13)\n    plt.yticks(fontsize= 13)\n    plt.savefig(\"β.png\",bbox_inches='tight')\n    plt.close()\n    \n     # log metrics\n    mlflow.log_metric('rmse',mean_squared_error(y_train,y_pred, squared=False))\n    mlflow.log_metric('r2',r2_score(y_train,y_pred))\n    mlflow.log_metric('mape',mean_absolute_percentage_error(y_train,y_pred))\n    mlflow.log_metric('mae',mean_absolute_error(y_train,y_pred))\n    mlflow.log_artifact(\"β.png\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"11db933f-27c0-4d4d-a29e-82ac742c6d12","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### test"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9a82f202-cbd6-49f8-8a04-5b378b5c048c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["with mlflow.start_run(run_name = 'Linear Regression') as run:\n    \n    # train the model\n    \n    lm = LinearRegression()\n    lm.fit(x_train,y_train)\n       \n    # use the model to predict the test data\n    \n    y_test_pred = lm.predict(x_test)\n   \n    # log parameters\n    mlflow.log_param('data','test')\n    mlflow.log_param('type','whole')\n    \n     # log metrics\n    mlflow.log_metric('rmse',mean_squared_error(y_test,y_test_pred, squared=False))\n    mlflow.log_metric('r2',r2_score(y_test,y_test_pred))\n    mlflow.log_metric('mape',mean_absolute_percentage_error(y_test,y_test_pred))\n    mlflow.log_metric('mae',mean_absolute_error(y_test,y_test_pred))\n    "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bace769a-71fa-46f6-9859-39c292c1834d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Ridge Regression"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d4328231-e61e-4d67-9e4c-f3dac5a4fa31","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### train"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f04f03b9-2c88-4122-b194-2229a816ca0c","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["#### CV"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c7605295-fb45-4d1e-8553-61ee3eb8061a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["\nwith mlflow.start_run(run_name = 'RidgeRegression') as run:\n    \n    \n    # model\n    \n    RR = Ridge()\n    \n     # log parameters\n    mlflow.log_param('type','CV')\n    \n    # cross validation\n    #tag\n    \n    alpha_values = {'alpha':[i*0.1  for i in range(90,120,2)]}\n    mlflow.set_tags(alpha_values)\n    \n    grid_search = GridSearchCV(RR, \n                           alpha_values,\n                           scoring=[\"r2\",'neg_root_mean_squared_error'],\n                           cv=10,\n                           refit='r2', \n                           return_train_score=True,\n                           n_jobs=-1)\n    \n    grid_search.fit(x_train,y_train)\n    \n\n    # log parameters\n    mlflow.log_param('best parameters',grid_search.best_params_)\n    mlflow.log_param('best estimator',grid_search.best_estimator_)\n    mlflow.log_param('best score',grid_search.best_score_)\n    \n    \n    plt.plot(grid_search.cv_results_['mean_test_neg_root_mean_squared_error'].tolist())\n    plt.savefig(\"test_rmse.png\")\n    plt.close()\n    \n    plt.plot(grid_search.cv_results_['mean_test_r2'].tolist())\n    plt.savefig(\"test_r2.png\")\n    plt.close()\n    \n     # log artifact\n    \n    mlflow.log_artifact(\"test_r2.png\")\n    mlflow.log_artifact(\"test_rmse.png\")    \n    "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8e70d028-c0ef-474c-b00f-6abe8f90b1f7","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### train_whole"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e9ab1956-16ad-4a7f-a3c0-2967f5b47a88","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["with mlflow.start_run(run_name = 'RidgeRegression') as run:\n      \n    # model\n    RR = Ridge(**grid_search.best_params_)\n    RR.fit(x_train,y_train)\n    y_pred = RR.predict(x_train)\n   \n    # log parameters\n    mlflow.log_param('data','train')\n    mlflow.log_param('type','whole')\n    \n    \n     # log metrics\n    mlflow.log_metric('rmse',mean_squared_error(y_train,y_pred, squared=False))\n    mlflow.log_metric('r2',r2_score(y_train,y_pred))\n    mlflow.log_metric('mape',mean_absolute_percentage_error(y_train,y_pred))\n    mlflow.log_metric('mae',mean_absolute_error(y_train,y_pred))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b413b443-60af-4171-8b30-6ab4e799958d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### test"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"10efc059-20ec-46b7-8068-f0bcbc9aa023","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["with mlflow.start_run(run_name = 'Ridge Regression') as run:\n    \n    RR = Ridge(**grid_search.best_params_)\n    \n    # train the model\n    \n    RR = Ridge(**grid_search.best_params_)\n    RR.fit(x_train,y_train)\n       \n    # use the model to predict the test data\n    \n    y_test_pred = RR.predict(x_test)\n   \n    # log parameters\n    mlflow.log_param('type','test')\n    \n     # log metrics\n    mlflow.log_metric('rmse',mean_squared_error(y_test,y_test_pred, squared=False))\n    mlflow.log_metric('r2',r2_score(y_test,y_test_pred))\n    mlflow.log_metric('mape',mean_absolute_percentage_error(y_test,y_test_pred))\n    mlflow.log_metric('mae',mean_absolute_error(y_test,y_test_pred))\n    "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1e4c0ead-b9da-42d0-87b6-cc42ca0f682f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Lasso Regression"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f127fa1d-00a4-4a8b-89bc-1bc2b93acc61","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### train"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dfa66f40-83a3-4060-8430-c41b68f5abe5","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["#### CV"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"053229e2-bbe8-4784-9330-147a93ebf25c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["\nwith mlflow.start_run(run_name = 'LassoRegression') as run:\n    \n    # model\n    \n    LS = Lasso()\n    \n     # log parameters\n    mlflow.log_param('type','CV')\n    \n    # cross validation\n    \n    alpha_values = {'alpha':[i*0.00001 for i in range(0,100,10)]}\n    mlflow.set_tags(alpha_values)\n    \n    grid_search_ls = GridSearchCV(LS, \n                           alpha_values,\n                           scoring=[\"r2\",'neg_root_mean_squared_error'],\n                           cv=10,\n                           refit='r2', \n                           return_train_score=True,\n                           n_jobs=-1)\n    \n    grid_search_ls.fit(x_train,y_train)\n\n    # log parameters\n    mlflow.log_param('best parameters',grid_search_ls.best_params_)\n    mlflow.log_param('best estimator',grid_search_ls.best_estimator_)\n    mlflow.log_param('best score',grid_search_ls.best_score_)\n    \n    \n    plt.plot(grid_search_ls.cv_results_['mean_test_neg_root_mean_squared_error'].tolist())\n    plt.savefig(\"test_rmse.png\")\n    plt.close()\n    \n    plt.plot(grid_search_ls.cv_results_['mean_test_r2'].tolist())\n    plt.savefig(\"test_r2.png\")\n    plt.close()\n    \n     # log artifact\n    \n    mlflow.log_artifact(\"test_r2.png\")\n    mlflow.log_artifact(\"test_rmse.png\")\n    "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d3a65ab3-392a-44c4-b114-333d565b7817","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py:29: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n  original_result = original(self, *args, **kwargs)\n/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n  model = cd_fast.enet_coordinate_descent(\n/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0017342599329817207, tolerance: 5.555311432212362e-07\n  model = cd_fast.enet_coordinate_descent(\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py:29: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n  original_result = original(self, *args, **kwargs)\n/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n  model = cd_fast.enet_coordinate_descent(\n/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0017342599329817207, tolerance: 5.555311432212362e-07\n  model = cd_fast.enet_coordinate_descent(\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### train_whole"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6480b838-9e7d-49ca-b42c-4e60b7a505fa","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["with mlflow.start_run(run_name = 'LassoRegression') as run:\n    \n    mlflow.set_tags(grid_search_ls.best_params_)\n    # model\n    \n    LS = Lasso(**grid_search_ls.best_params_)\n    LS.fit(x_train,y_train)\n    y_pred = LS.predict(x_train)\n   \n    # log parameters\n    mlflow.log_param('data','train')\n    mlflow.log_param('type','whole')\n    \n     # log metrics\n    mlflow.log_metric('rmse',mean_squared_error(y_train,y_pred, squared=False))\n    mlflow.log_metric('r2',r2_score(y_train,y_pred))\n    mlflow.log_metric('mape',mean_absolute_percentage_error(y_train,y_pred))\n    mlflow.log_metric('mae',mean_absolute_error(y_train,y_pred))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"802d407f-718e-4f3a-b714-51f8fabd22b8","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py:29: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n  original_result = original(self, *args, **kwargs)\n/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n  model = cd_fast.enet_coordinate_descent(\n/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0017342599329817207, tolerance: 5.555311432212362e-07\n  model = cd_fast.enet_coordinate_descent(\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py:29: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n  original_result = original(self, *args, **kwargs)\n/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n  model = cd_fast.enet_coordinate_descent(\n/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0017342599329817207, tolerance: 5.555311432212362e-07\n  model = cd_fast.enet_coordinate_descent(\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### test"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"65262e2f-da98-4c31-8846-e21e579a702e","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["with mlflow.start_run(run_name = 'LassoRegression') as run:\n    \n    # train the model\n    mlflow.set_tags(grid_search_ls.best_params_)\n    \n    LS = Lasso(**grid_search_ls.best_params_)\n    LS.fit(x_train,y_train)\n    \n    y_test_pred = LS.predict(x_test)\n   \n    # log parameters\n    mlflow.log_param('type','test')\n    \n     # log metrics\n    mlflow.log_metric('rmse',mean_squared_error(y_test,y_test_pred, squared=False))\n    mlflow.log_metric('r2',r2_score(y_test,y_test_pred))\n    mlflow.log_metric('mape',mean_absolute_percentage_error(y_test,y_test_pred))\n    mlflow.log_metric('mae',mean_absolute_error(y_test,y_test_pred))\n    "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a03b0916-a1cc-41ef-8a59-ed3cc9c8e8cc","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py:29: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n  original_result = original(self, *args, **kwargs)\n/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n  model = cd_fast.enet_coordinate_descent(\n/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0017342599329817207, tolerance: 5.555311432212362e-07\n  model = cd_fast.enet_coordinate_descent(\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["/databricks/python_shell/dbruntime/MLWorkloadsInstrumentation/_sklearn.py:29: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n  original_result = original(self, *args, **kwargs)\n/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n  model = cd_fast.enet_coordinate_descent(\n/databricks/python/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0017342599329817207, tolerance: 5.555311432212362e-07\n  model = cd_fast.enet_coordinate_descent(\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Random Forest"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c4be7fd5-12ab-44cf-9de7-f6633c1bd3bc","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### train"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"deb98851-d83a-4547-b892-d9d51aa9a8c6","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["#### CV"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"195acb2c-687f-4957-9aa1-e7a7ea964d56","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#grid\nwith mlflow.start_run(run_name = 'RandomForest') as run:\n    \n    # model\n    \n    RF = RandomForestRegressor()\n    \n     # log parameters\n    mlflow.log_param('type','CV')\n        \n   # params = [{'n_estimators':[i for i in range(10,200,30)],#Number of Trees\n              # 'max_depth':[i for i in range(1,30,1)],# Tree Depth\n             #   'max_features':[i for i in range(1,18,1)],\n            #  'min_samples_split': [i for i in range(2,20,1)], #The minimum number of samples required to split an internal node\n            #   'min_samples_leaf': [i for i in range(1,20,1)], #The minimum number of samples required to be at a leaf node\n           \n    \n    params = [{'n_estimators':[126],#Number of Trees\n              'max_depth':[13],# Tree Depth\n             'max_features':[3],\n             'min_samples_split': [5], #The minimum number of samples required to split an internal node\n             'min_samples_leaf': [i for i in range(1,20,1)], #The minimum number of samples required to be at a leaf node\n           \n             \n              }\n             ]\n    \n    mlflow.set_tags(params[0])\n    \n    grid_search = GridSearchCV (RF, \n                           param_grid= params,\n                           scoring=[\"r2\",'neg_root_mean_squared_error'],\n                           cv=10,        \n                           refit='r2', \n                           return_train_score=True,\n                           n_jobs=-1)\n    \n    grid_search.fit(x_train,np.ravel(y_train))\n    \n    # log parameters\n    mlflow.log_param('best parameters',grid_search.best_params_)\n    mlflow.log_param('best estimator',grid_search.best_estimator_)\n    mlflow.log_param('best score',grid_search.best_score_)\n    \n    \n    plt.plot(grid_search.cv_results_['mean_test_neg_root_mean_squared_error'].tolist())\n    plt.savefig(\"test_rmse.png\")\n    plt.close()\n    \n    plt.plot(grid_search.cv_results_['mean_test_r2'].tolist())\n    plt.savefig(\"test_r2.png\")\n    plt.close()\n    \n     # log artifact\n    \n    mlflow.log_artifact(\"test_r2.png\")\n    mlflow.log_artifact(\"test_rmse.png\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bef23edf-4ee7-4e37-b39a-3363a7750e6d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### train_whole"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b9225aa9-ad25-489a-a460-0eca1e7bb19b","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["with mlflow.start_run(run_name = 'RandomForest') as run:\n    \n    mlflow.set_tags(grid_search.best_params_)\n    # model\n    \n    RF = RandomForestRegressor(**grid_search.best_params_)\n    RF.fit(x_train,np.ravel(y_train))\n    y_pred = RF.predict(x_train)\n   \n    # log parameters\n    mlflow.log_param('data','train')\n    mlflow.log_param('type','whole')\n    \n    \n     # log metrics\n    mlflow.log_metric('rmse',mean_squared_error(y_train,y_pred, squared=False))\n    mlflow.log_metric('r2',r2_score(y_train,y_pred))\n    mlflow.log_metric('mape',mean_absolute_percentage_error(y_train,y_pred))\n    mlflow.log_metric('mae',mean_absolute_error(y_train,y_pred))   \n    "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fbb845b0-cc4a-411f-923c-02291f8264f9","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### test"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"257a4cc3-2cda-4293-a79b-29b4e776d6d6","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["with mlflow.start_run(run_name = 'RandomForest') as run:\n    \n    RF = RandomForestRegressor(**grid_search.best_params_)\n    RF.fit(x_train,np.ravel(y_train))\n       \n    # use the model to predict the test data\n    \n    y_test_pred = RF.predict(x_test)\n   \n    # log parameters\n    mlflow.log_param('type','test')\n    \n     # log metrics\n    mlflow.log_metric('rmse',mean_squared_error(y_test,y_test_pred, squared=False))\n    mlflow.log_metric('r2',r2_score(y_test,y_test_pred))\n    mlflow.log_metric('mape',mean_absolute_percentage_error(y_test,y_test_pred))\n    mlflow.log_metric('mae',mean_absolute_error(y_test,y_test_pred))\n    "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0ae14f64-5017-4bef-af14-0dabbd7d23c2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Day125_decay","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":4289401610927295}},"nbformat":4,"nbformat_minor":0}
